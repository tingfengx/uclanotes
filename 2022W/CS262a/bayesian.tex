\documentclass[11pt]{article}

\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[
    xetex, 
    dvipsnames
]{xcolor}
\usepackage[
    colorlinks=true,
    linkcolor=black,
    urlcolor=Thistle
]{hyperref}
\usepackage{fancyhdr}
\usepackage{datetime}
\usepackage{xargs}
\usepackage{ccicons}
\usepackage{mdframed}
\usepackage{caption}
\usepackage{cancel}
\usepackage{parskip}
\usepackage{float}
\usepackage[nottoc]{tocbibind}
%\usepackage[
%    outputdir=.texpadtmp
%]{minted}

% ==== License =====
\usepackage[
    type={CC}, 
    modifier={by-nc-sa}, 
    version={4.0},
]{doclicense}

% ==== set font ====
\usepackage{amsmath}
\usepackage{unicode-math}
%\setmainfont{texgyrepagella-regular.otf}
\setmainfont{Palatino}
\setmathfont{texgyrepagella-math.otf}

% ==== todo notes ====
\usepackage[
    colorinlistoftodos,
    prependcaption,
    textsize=tiny
]{todonotes}
\newcommandx{\note}[2][1=]{\todo[linecolor=Thistle,backgroundcolor=Thistle!25,bordercolor=Thistle,#1]{#2}}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}

% General
\newcommand{\mc}[1]{\mathcal{#1}}

% Math Bold Font, Vector Notations
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\be}{\mathbf{e}}
\renewcommand{\bf}{\mathbf{f}}
\newcommand{\bg}{\mathbf{g}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bi}{\mathbf{i}}
\newcommand{\bj}{\mathbf{j}}
\newcommand{\bk}{\mathbf{k}}
\newcommand{\bl}{\mathbf{l}}
\newcommand{\bm}{\mathbf{m}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bo}{\mathbf{o}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bzero}{\mathbf{0}}

% Proofs, Structures
\newcommand{\proof}{\tit{\underline{Proof:}}} % This equivalent to the \begin{proof}\end{proof} block
\newcommand{\proofforward}{\tit{\underline{Proof($\implies$):}}}
\newcommand{\proofback}{\tit{\underline{Proof($\impliedby$):}}}
\newcommand{\proofsuperset}{\tit{\underline{Proof($\supseteq$):}}}
\newcommand{\proofsubset}{\tit{\underline{Proof($\subseteq$):}}}
\newcommand{\contradiction}{$\longrightarrow\!\longleftarrow$}
\newcommand{\qed}{\hfill $\blacksquare$}

% Number Spaces, Vector Space
\newcommand{\R}{\mathbb{R}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\field}{\mathbb{F}}

% customized commands
\newcommand{\settag}[1]{\renewcommand{\theenumi}{#1}}
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\tit}[1]{\textit{#1}}
\newcommand{\largeover}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\newcommand{\double}[1]{\mathbb{#1}} % Set to behave like that on word
\newcommand{\trans}[3]{$#1:#2\rightarrow{}#3$}
\newcommand{\map}[3]{\text{$\left[#1\right]_{#2}^{#3}$}}
\newcommand{\dime}[1]{\mathrm{dim}(#1)}
\newcommand{\mat}[2]{M_{#1 \times #2}(\R)}
\newcommand{\aug}{\fboxsep=-\fboxrule\!\!\!\fbox{\strut}\!\!\!}
\newcommand{\basecase}{\textsc{\underline{Basis Case:}} }
\newcommand{\inductive}{\textsc{\underline{Inductive Step:}} }
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\independent}{\perp \!\!\! \perp}

\newcommand{\mods}{\mathrm{Mods}}
\newcommand{\pr}{\mathrm{Pr}}
\newcommand{\ent}{\mathrm{ENT}}
\newcommand{\mi}{\mathrm{MI}}
\newcommand{\dsep}{\mathrm{dsep}}

% Set section number in front of equation enumerations
\counterwithin{equation}{section}
\counterwithin{footnote}{section}
\author{\ccLogo\, Tingfeng Xia @ UCLA}
\title{CS262a Bayesian Networks}
\date{Winter Quarter, 2022}

\begin{document}
\maketitle
\doclicenseThis

\section*{Preface}
This document is intentionally kept short, and is not a complete summary of what is covered in this course. Excerpt from online: 
\begin{quotation}
\noindent The objective of this class is to provide an in-depth exposition of knowledge representation, reasoning, and machine learning under uncertainty using the framework of Bayesian networks. Both theoretical underpinnings and practical considerations will be covered, with a special emphasis on constructing and learning graphical models, and on various exact and approximate inference algorithms. Additional topics include logical approaches to probabilistic inference, compilation techniques, sensitivity analysis, undirected graphical models, and statistical relational learning.
\end{quotation}

\paragraph{Instructor:} \href{https://web.cs.ucla.edu/~darwiche/}{Professor Adnan Darwiche}
\paragraph{Book:} \href{https://www.cambridge.org/us/catalogue/catalogue.asp?isbn=9780521884389}{Adnan Darwiche. Modeling and Reasoning with Bayesian Networks. Cambridge University Press 2009.}

\tableofcontents

\newpage
\section{Propositional Logic}
\subsection{Principle Logical Forms}
\paragraph{Inconsistent.} Something that never holds; $\mods (\cdot) = \empty$; $\pr(\alpha) = 0$
\paragraph{Valid.} Something that always holds; $\mods (\cdot) = \Omega$; $\pr (\alpha) = 1$
\paragraph{Equivalent.} $\mods (\alpha) = \mods (\beta)$
\paragraph{Mutual Exclusive.} $\mods(\alpha) \cap \mods (\beta) = \emptyset$
\paragraph{Exhaustive.} $\mods (\alpha) \cup \mods (\beta) = \Omega$
\paragraph{Entailment / Implication.} $\alpha \vDash \beta \triangleq \mods (\alpha) \subseteq \mods ( \beta)$

\subsection{Equivalent Forms}
\begin{itemize}
\item $\mods( \alpha \land \beta) = \mods( \alpha) \cap \mods(\beta)$
\item $\mods( \alpha \vee \beta) = \mods ( \alpha) \cup \mods ( \beta)$
\item $\mods ( \neg \alpha) = \largeover{\mods ( \alpha)}$
\end{itemize}

\subsection{Instantiation Agreement}
Two instantiation, each of which can cover a subset of different varaibles, are said to be compatible with each other if they argree on all common variables. Denoted as $\bx \sim \by$.

\subsection{Information Theory}
\paragraph{Entropy.} 
\begin{equation}
\ent  (X) = - \sum_x \pr (x) \log \pr( x)
\end{equation}
where $0 \log 0 = 0 $ by convention. With a higher entropy, we say that it is more chaotic. 

\paragraph{Conditional Entropy. }
\begin{equation}
	\ent (X | Y ) = \sum_y \pr (y) \ent(X | y) \quad \text{where} \quad \ent (X|y) = - \sum_{x} \pr(x|y) \log \pr(x | y)
\end{equation}
Conditioning never increases the entropy, i.e. 
\begin{equation}
	\ent (X | Y) \leq \ent (X)
\end{equation}

\paragraph{Mutual Information} 
\begin{align}
	\mi(X; Y) 
	&= \sum_{x, y} \pr (x, y) \log \frac{\pr (x, y)}{\pr (x) \pr (y)} \\
	&= \ent (X) - \ent (X | Y) \\
	&= \ent (Y) - \ent ( Y | X) 
\end{align}

\paragraph{Conditional Mutual Information}
\begin{align}
	\mi ( X; Y | Z) 
	&= \sum_{x, y, z} \pr (x, y , z) \log \frac{\pr (x, y | z)}{\pr (x | z) \pr(y | z)} \\
	&= \ent (X | Z) - \ent (X | Y, Z) \\
	&= \ent (Y | Z) - \ent (Y | X, Z)
\end{align}

\section{Probability Calculus}
\subsection{Bayesian Conditioning}
Bayesian Condition is specified by the formula 
\begin{equation}
	\pr ( \alpha | \beta) = \frac{\pr ( \alpha \land \beta )}{\pr ( \beta) }
\end{equation}
In particular, not to be confused with Bayesian inference (to be added later). 

\subsection{Independence and Notations}
\paragraph{Independence.}  
\begin{align}
	\alpha \independent \beta 
	& \iff \pr ( \alpha | \beta) = \pr ( \alpha) \vee \pr( \beta) = 0 \\
	& \iff \pr ( \alpha \land \beta) = \pr(\alpha) \pr ( \beta)
\end{align}

\paragraph{Conditional Independence.}
\begin{align}
	(\alpha \independent \beta) | \gamma 
	&\iff \pr ( \alpha | \beta \land \gamma) = \pr ( \alpha | \gamma) \vee \pr(\beta \land \gamma) = 0 \\
	&\iff \pr ( \alpha \land \beta | \gamma) = \pr ( \alpha | \gamma ) \pr(\beta | \gamma ) \vee \pr ( \gamma) = 1
\end{align}

\paragraph{Set Independence}
\begin{equation}
	I_{\pr} (X, Z, Y) \iff (x \independent y) | z, \quad \forall x, y, z \in X, Y, Z
\end{equation}

\section{Bayesian Networks}
\subsection{Soft Evidence}
\subsubsection{All Things Considered Method}
We normalize / rescale $w$ according to new evidence. 
\begin{align}
\pr' (w) = \begin{cases}
	\frac{\pr ' (\beta)}{\pr (\beta)} \pr ( w) &  \text{if} w \vDash \beta \\
	\frac{\pr' (\neg \beta)}{\pr (\neg \beta)} \pr (w) & \text{if} w \vDash \neg \beta
\end{cases}
\end{align}

The closed form is called the Jefferey's Rule. 

\paragraph{Jeffery's Rule}
\begin{equation}
	\pr ' (\alpha) = q \pr ( \alpha | \beta ) + (1 - q) \pr ( \alpha | \neg \beta)
\end{equation}

\paragraph{Jeffery's Rule - General Case}
\begin{equation}
	\pr'(\alpha) = \sum_{i = 1}^n\pr ' (\beta_i) \pr( \alpha | \beta_i) 
\end{equation}

\subsubsection{Nothing-else Considered Method}
\paragraph{Odds. } 
\begin{equation}
	O(\beta) = \frac{\pr( \beta)}{\pr ( \neg \beta)}
\end{equation}

\paragraph{Bayes Factor} 
\begin{equation}
	k = \frac{O'(\beta)}{O ( \beta)} = \frac{Pr'(\beta) / \pr'(\neg \beta)}{...}
\end{equation}
from where we can expand and organize
\begin{equation}
	\pr' ( \beta) = \frac{k \pr ( \beta) }{k \pr ( \beta) + \pr ( \neg \beta) } 
\end{equation}

\paragraph{Closed Form Solution.}
\begin{equation}
	\pr' (\alpha) = \frac{k\pr ( \alpha \land \beta) + \pr (\alpha \land \neg \beta)}{k \pr ( \beta ) + \pr ( \neg \beta)}
\end{equation}

\subsection{Noisy Sensors}
\begin{equation}
	O'(\beta) = \underbrace{\frac{1 - f_n}{f_p}}_{k^+} O(\beta) \quad \quad O'(\beta) = \underbrace{\frac{f_n }{1 - f_p}}_{k^-} O(\beta)
\end{equation}

\subsection{Markov Assumptions}
\begin{equation}
	\mathrm{Markov}(G) = \{I_\pr ( V, \mathrm {Parents} (V), \mathrm{ND} (V) \}_V
\end{equation}
where $\mathrm{ND}$ means non-descendants, and includes all nodes except for $V, \mathrm {Parents} (V)$ and $\mathrm {Descendants}(V)$ (all the way till leaf)

\subsection{Graphoid Axioms\label{sec:graphoid}}
\paragraph{Symmetry.}
\begin{equation}
	I_\pr (X, Z, Y) \iff I _\pr (Y, Z, X) 
\end{equation}

\paragraph{Decomposition.}
\begin{equation}
	I_\pr (X, Z, Y \cup W) \implies I _\pr (X, Z, Y) \land I _\pr (X, Z, W)
\end{equation}

\paragraph{Weak Union.}
\begin{equation}
	I_\pr (X, Z, Y \cup W) \implies I_\pr (X, Z \cup Y, W) 
\end{equation}

\paragraph{Contraction.}
\begin{equation}
	I_\pr (X, Z, Y) \land I_\pr (X, Z \cup Y, W ) \implies I_\pr (X, Z, Y \cup W )
\end{equation}

\paragraph{Triviality.}
\begin{equation}
	I_\pr (X, Z, \emptyset) 
\end{equation}

\subsection{Positive Graphoid Axioms}
... includes everything from Graphoid Axioms (Section \ref{sec:graphoid}) and in addition has 
\paragraph{Intersection.}
\begin{equation}
	I _ \pr (X, Z \cup W, Y ) \land I _\pr (X, Z \cup Y , W ) \implies I _\pr (X, Z, Y \cup W)
\end{equation}

\subsection{D-seperation and Graphical Rules}
There are three types of valves to consider, 
\begin{itemize}
	\item A sequential valve ($\rightarrow W \rightarrow$) is closed iff variable $W$ appears in $\mathbf Z$, 
	\item A divergent valve ($\leftarrow W \rightarrow$) is closed iff variable $W$ appears in $\mathbf Z$, and 
	\item A convergent valve ($\rightarrow W \leftarrow$) is closed iff neither variable $W$ not any of its descendants appears in $\mathbf Z$. \footnote{This will be referred to as a collider node later, as it is one that behaves differently from the rest two.}
\end{itemize}

\subsection{D-seperation Linear Prune Theorem}
(Theorem 4.1) Testing whether $\mathbf X$ and $\mathbf Y$ are d-separated by $\mathbf Y$ in a DAG $G$ is equivalent to testing whether $\mathbf X$ and $\mathbf Y$ are disconnected\footnote{Disregard arrows, we only care about connectedness here.} in a new DAG $G'$, which is obtained by pruning DAG as follows: 
\begin{itemize}
	\item We delete any leaf node $W$ from DAG $G$ as long as $W\not \in \mathbf X\cup \mathbf Y \cup \mathbf Z$. This process is repeated until no more nodes can be deleted. 
	\item We delete all edges outgoing from nodes in $\mathbf Z$, the evidence set. 
\end{itemize}


\subsection{D-seperation Properties}
\paragraph{Soundness.} 
\begin{equation}
	\dsep_ G ( X, Z, Y ) \implies I _\pr (X, Z, Y)
\end{equation}

\paragraph{(Weak) Completeness.}
There exists a parametrization $\Theta$ that for every DAG $G$ such that
\begin{equation}
	I_\pr (X, Z, Y) \iff \dsep_G (X, Z, Y)
\end{equation}

\section{Inference by Variable Elimination}
\subsection{Interaction Graphs}
The interaction graph is a tool to help us determine the run time complexity of variable elimination. Also it can help us choose elimination order. (Heuristics described in Section \ref{sec:elimination order}. It is defined as follows: Let $f_1, ..., f_n$ be a set of factors. The interaction graph $G$ of these factors is an undirected graph constructed as follows. The nodes of $G$ are the variables that appear in factors $f_1, ..., f_n$. There is an edge between two variables in $G$ iff those variables appear in he same factor. 

The interaction graph is a living creature, meaning that it is continuously updated as we perform variable elimination. When we eliminate a node $n$, we have to add edges (if necessary) to make sure all neighbors of $n$ are fully connected. 

\paragraph{Order Width.} The order width can be determined by keeping track of the evolving interaction graphs. Order width is defined as the maximum number of neighbors when nodes is deleted from the interaction graph. Of course, we have to add edges (if necessary) after every deletion.

\subsection{Elimination Order\label{sec:elimination order}} Choosing an optimal elimination order in VE is NP-hard. We resort to heuristics. 

\paragraph{Minimum Degree Ordering.}
When choosing node to eliminate, choose the one that has the smallest number of neighbours in the interaction graph. 

\paragraph{Minimum Fill Ordering.}
..., choose the one that results in minimum number of newly added edge in the interaction graph. 

\subsection{Tree Width}
Tree width is the smallest possible elimination order width for a network. The tree width quantifies the the extent to which a network resembles a tree structure. The more similar a network is to a tree structure, the smaller the tree width. No complete elimination order can have have an order width less than network tree width. Also, there always exists an elimination order that has order width the same as tree width. However, determining this order is NP-hard. 

\paragraph{Poly-Tree Tree Width.} Poly trees have known tree width of $k$ where $k$ is the maximum number of parents that any node may have. 

\section{Inference by Factor Elimination}
\subsection{Factor Elimination}
The elimination of factor $f_i$ from a set of factors $S$ is a two step process. We first eliminate all variables $V$ that appear only in factor $f_i$ and then multiply the result $\sum_V f_i$ by some other factor $f_j \in S$. 

\paragraph{Projection.} Factor projection operation is defined as 
\begin{equation}
	\mathrm {project} (f, Q) \triangleq \sum_{vars(f) - Q} f
\end{equation}
which is essentially summing out all variables not in $Q$. In the vanilla factor elimination algorithm (\texttt{FE1}), the projection is used in the return statement. This is essentially a normalization step (onto variables specified only).

\subsection{Elimination Trees\label{sec:elimination tree}}
\paragraph{Variables.}
$vars(i)$ denotes the variables mentioned at node $i$. $vars(i, j)$ denotes all variables mentioned in nodes to the $i$-side of the graph (inclusive). Hence, it holds that $vars(i) \subseteq vars(i, j)$.

\paragraph{Separators.} 
\begin{equation}
	S_{ij} \triangleq vars(i, j) \cap vars(j, i)
\end{equation}

\paragraph{Clusters.} 
\begin{equation}
	C_i \triangleq vars(i) \cup \bigcup_j S_{ij}
\end{equation}

\subsection{Message Passing Formulation}
The Message that $i$ sends to $j$ is 
\begin{equation}
	M_{ij} \triangleq \mathrm{project} \left( \phi_i \prod_{k \neq j } M_{ki}, S_{ij} \right) 
\end{equation}
where the product is off all the messages from edges except for the output direction and $S_{ij}$ is the separator defined in Section \ref{sec:elimination tree}.


\section{Inference by Conditioning}
\subsection{Run time Comparison}
\subsubsection{Variable Elimination (VE)}
Let $w$ be the width of the tree, $n$ denote the number of variables, and $|Q|$ as query variable size.
\paragraph{Time Complexity.} $\mathcal O (n \exp (w))$

\paragraph{Space Complexity.} 
\begin{equation}
	\mathcal O (n \exp (w) + n \exp (|Q|)) \equiv \mathcal O (n \exp (w)) \text{, \quad if } |Q| < \infty
\end{equation}

\subsubsection{Massage Passing}
\paragraph{One Specific Message.} The cost to pass one specific message is
\begin{equation}
	\mathcal O (\exp ( |C_i|)) 
\end{equation}
where $|C_i|$ is the cluster size. 

\paragraph{Every Message.} Since cluster sizes are bounded above by tree width, we can say that passing of every message will have an upper-bound runtime of
\begin{equation}
	\mathcal O ( \exp (w) )
\end{equation}
where $w$ is the width of the elimination tree. 

\paragraph{Amount of Messages.} The total amount of messages is 
\begin{equation}
	\mathcal O (2 (m - 1)) \quad \quad \text{where $m = |V|$}
\end{equation}
since we have a tree structure, meaning we have exactly $(m - 1)$ edges and each edge can have forward backward each once. 

\paragraph{All Messages - All Cluster Marginals.} The total time to pass all messages and compute all cluster marginals is 
\begin{equation}
	\mathcal O (m \exp (w)) \quad \quad \text{or} \quad \quad \mathcal O (n \exp( w))\text{, for $\mathcal O (n)$ edges.} 
\end{equation}

\subsubsection{Polytree / Belief Propagation}
\paragraph{Runtime.} Define $k$ as the max number of parents in the poly tree, then $k$ is the same as the width of elimination tree. Let, also, $n$ denote the number of nodes in the polytree. The algorithm has runtime 
\begin{equation}
	\mathcal O (n \exp (k))
\end{equation}

\subsubsection{Cut Set Conditioning}
\paragraph{Time and Space (Total) Complexity.}
\begin{equation}
	\mathcal O (n \exp (k))\quad \quad \text{where $n = |N|$ and $k$ is width}
\end{equation}

\subsubsection{Any Space Recursive Cut Set}
\begin{table}[H]
\centering
\begin{tabular}{l|l|l|c} \label{tab:anytime comparison}
      & no cache                           & all cache                 & $\Delta\, no \rightarrow all$ \\ \hline
space & $\mathcal O (wn)$                  & $\mathcal O (n \exp (w))$ & $\uparrow$       \\
time  & $\mathcal O (n \exp (w \log n )))$ & $\mathcal O (n \exp (w))$ & $\downarrow$    
\end{tabular}
\end{table}


\section{Compiling Bayesian Networks}
\subsection{Network Polynomials}
The network polynomial is a summation over all instantiations of a network, 
\begin{equation}
	f \triangleq \sum_z \prod_{\theta_{x | u} \sim z }\theta _{x | u} \prod _{\lambda _x \sim z} \lambda_x
\end{equation}

\subsection{AC Properties}
\paragraph{AC Size.}
of an AC is defined as the number of edges in the circuit.  
\paragraph{AC Complexity.}
is the size of smallest AC that represents the network polynomial. 

\paragraph{Decomposable.}
At each $\star$ node, we need 
\begin{equation}
	vars(AC_A) \cap vars(AC_B) = \emptyset
\end{equation}

\paragraph{Deterministic.}
At each $+$ node, we require at most one positive input is non-zero for all \textit{complete instantiation}. 

\paragraph{Smooth.}
At each $+$ node, we require 
\begin{equation}
	vars(AC_A) = vars(AC_B)
\end{equation}

\paragraph{AC for Marginals.} requires decomposable and smooth. This guarantees that sub-circuits are of complete variable instantiations. 

\paragraph{AC for Marginals and MPE.} requires all three above: decomposable, deterministic, and smooth. The additional determinism guarantees a 1-to-1 mapping between sub-circuits and complete variable instantiations. 

\subsection{AC Derivative Probabilistic Implications}
\begin{equation}
	\frac{\partial f}{\partial \lambda _\bx} (\be) = \pr( \bx, \be - \mathbf X) 
\end{equation}
where the notation $\be - \mathbf X$ means the instantiation that results form erasing the values of variables $\mathbf X$ from instantiation $\be$\footnote{For example, $\mathbf e = ab \overbar c$, then $\be - A = b\overbar c$ and $\be - AC = b$}, and 
\begin{equation}
	\theta_{\bx | \bu} \frac{\partial f}{\partial \theta_{\bx | \bu}} ( \be) = \pr (\bx, \bu, \be)
\end{equation}

\subsection{Compilation via Variable Elimination}
\paragraph{Circuit Factors.}
``In a circuit factor, each variable instantiation is mapped to a circuit node instead of a number.''

\paragraph{Operations.}
We use $+(n_1, n_2)$ to denote an addition node that has $n_1$ and $n_2$ as its children. Similarly, $\star (n_1, n_2)$ denotes a multiplication node. An operation (multiplication or addition) of two circuit factors $f(X)$ and $f(Y)$ is a factor over variables $Z = X \cup Y$, 
\begin{equation}
	f(z) = [\star \text{ or } +]( f(x), f(y)), \quad \text{ where } x \sim z \quad \text{and} \quad y \sim z 
\end{equation}

\paragraph{Procedure.}
\begin{enumerate}
	\item \textbf{Make nodes for each CPT.} For each family $X|U$, construct nodes $\star (\lambda_x, \theta_{x | u} )$ for each instantiation $xu$ of $XU$. 
	\item \textbf{Eliminate Everything.} We apply VE to eliminate all variables in the network to reach trivial instantiation $\top$ (corresponds to root). During the process, we construct the tree using the operations defined above: $* / +$. 
\end{enumerate}

\section{Maximum Likelihood Learning}
\subsection{Empirical Distribution}
A dataset $D$ for variables $\mathbf X$ is a vector $\bd_1, ..., \bd_N$ where each $\bd_i$ is called a case and represents a partial instantiation of variables $\mathbf X$. The data set is called complete if each case is a complete instantiation of variables $\mathbf X$; otherwise the dataset is called incomplete. The empirical distribution in the case of complete dataset is defined as
\begin{equation}
	\pr_D (\alpha ) \triangleq \frac{D\#(\alpha)}{N}
\end{equation}
where $D\#(\alpha)$ is the number of cases $\mathbf d_i$ in the data set $D$ that satisfy event $\alpha$, i.e.  $\bd_i \vDash \alpha$. 

\subsection{Complete Data MLE\label{sec:compete data mle}}
When the dataset is complete, the definition of empirical distribution above suggests the following \textbf{maximum likelihood estimates}
\begin{equation}
	\theta^{ml}_x \triangleq \pr_D(x) = \frac{D\#(x)}{N} 
\end{equation}
\begin{equation}
	\theta^{ml}_{x|\bu} \triangleq \pr_D (x | \bu) = \frac{D\# (x, \bu)}{D\# (\bu)}
\end{equation}
This formulation maximizes the likelihood, i.e., 
\begin{equation}
	\theta^{ml} = \arg\max _\theta L(\theta |D ) = \arg\max _\theta \prod_{i = 1}^N \pr_\theta (\bd_i)
\end{equation}
In addition, maximum likelihood estimates minimizes the KL divergence between the learnt bayesian network and the empirical distribution, i.e., 
\begin{equation}
	\arg\max_\theta L(\theta| D) = \arg\min_\theta D_{KL} (\pr_D (\mathbf X), \pr_\theta (\mathbf X))
\end{equation}

\paragraph{Distribution of Estimates.} The distribution of ML estimates $\theta_{x|\bu}^{ml}$ is asymptotically normal, converges in distribution to 
\begin{equation}
	\mathrm{Gaussian} \left ( 
	\mu = \pr(x | \bu ), \sigma = \frac{\pr(x | \bu) (1 - \pr(x | \bu)) }{N \cdot \pr(\bu) }
	\right) 
\end{equation}
Notice that as sample size $N$ increases, the variance of this distribution decreases. 

\subsection{Incomplete Data EM}
EM algorithm first completes the dataset, which induces an empirical distribution, and then uses it to estimate parameters the same way we did in Section \ref{sec:compete data mle}. The new set of parameters are guaranteed to have no less likelihood than the initial parameters, so this process is repeated until convergence criteria is met. 

\paragraph{Expected Empirical Distribution 1.} The expected empirical distribution of dataset $D$ under parameters $\theta^k$ is defined as 
\begin{equation}
	\pr_{D, \theta^k} (\alpha) \triangleq \sum_{\bd_i, \bc_i \vDash \alpha} \pr_{\theta^k}(\bc_i, \bd_i)
\end{equation}
where $\alpha$ is an event and $\mathbf C_i$ are the variables with missing values in case $\bd_i$. 

\paragraph{EM Estimates 1.}  The EM estimates for dataset $D$ and parameters $\theta^k$ are defined as 
\begin{equation}
	\theta_{x|\mathbf u}^{k + 1} \triangleq \pr_{D, \theta^k} (x|\bu)
\end{equation}

\paragraph{Expected Empirical Distribution 2.} The expected empirical distribution of data set $D$ given parameters $\theta^k$ can be computed as 
\begin{equation}
	\pr_{D, \theta^k} (\alpha) = \frac{1}{N} \sum_{i = 1}^N \pr_{\theta^k}  (\alpha | \bd_i)
\end{equation}

\paragraph{EM Estimates 2.} Now the EM estimates for dataset $D$ and parameters $\theta^k$ can be computed as\footnote{This is to say that the EM estimates can be computed without constructing the expected empirical distribution.}
\begin{equation}
	\theta_{x} ^{k + 1} = Pr_{D, \theta^k} (x) = (1/N) \sum_{i = 1}^N Pr_{\theta^k} (x | \bd_i)
\end{equation}
and
\begin{equation}
	\theta_{x|\bu}^{k + 1} = \frac{\sum_{i= 1}^N \pr_{\theta^k} (x\bu | \bd_i)}{\sum_{i = 1}^N \pr_{\theta^k} (\bu | \bd_i)}
\end{equation}

\paragraph{Difference.} The key difference is that in \textbf{EME2} does not reference the expected empirical distribution (there is no $D$ in the subscript of $\pr$; while \textbf{EME1} does reference. Instead, \textbf{EME2} computes EM estimates by performing inference on a bayesian network parameterized by the previous parameter estimates $\theta^k$.  

\subsection{Graph Structure Learning}
\paragraph{Conditional Entropy.}
\begin{equation}
	\ent_D (X | \mathbf U ) = - \sum_{x\bu} \pr_D (x \bu) \log_2 \pr_D(x | \bu)
\end{equation}

\paragraph{Log-Likelihood.}
\begin{equation}
	\mathrm {LL}(G|D) = -N \sum_{X\mathbf U} \ent_D(X | \mathbf U)
\end{equation}
where $X\mathbf U$ are families in the structure $G$ and $D$ is a complete dataset of size $N$. 

\paragraph{Mutual Information.}
\begin{equation}
	\mathrm {MI}_D (X, U) = \sum_{x, u} \pr_D(x, u) \log\frac{\pr_D(x, u)}{\pr_D(x) \pr_D(u)}
\end{equation}

\paragraph{Tree-Score Measure}
\begin{equation}
	tScore(G|D) = \sum_{U \rightarrow X} \mathrm {MI}_D (X, U)
\end{equation}

\paragraph{Scores - General}
The dimension of a DAG $G$ is defined as
\begin{equation}
	||G|| = \sum_{i = 1}^n ||X_i \mathbf U_i ||
\end{equation}
where family size 
\begin{equation}
	||X_i \mathbf U_i || = (X_i^\# - 1) \mathbf U_i^\#
\end{equation}
In general, scores could be written as 
\begin{equation}
	Score(G|D) = \mathrm{LL}(G|D) - \psi (N) ||G||
\end{equation}

\paragraph{Akaike Information Criterion (AIC).} is when we choose $\psi (N)$ to be a constant independent of $N$. 

\paragraph{Minimum Description Length (MDL).} is when we take
\begin{equation}
	\psi(N) = \frac{\log_2 N}{2}
\end{equation} 

\section{Bayesian Learning}
\subsection{Meta Network}
The meta network is a tiled version of a base bayesian network, with extra (root) variables pointing into base network nodes. Meta network of size $N$ means it has $N$ copies of the original network within. It satisfies the following \textbf{parameter independence} relationships: let $\Sigma_1, \Sigma_2$ each contain a collection of parameter sets, and $\Sigma_1 \cap \Sigma_2 = \emptyset$. Then, 
\begin{itemize}
	\item $\Sigma_1$ and $\Sigma_2$ are independent, $\mathbb P (\Sigma_1, \Sigma_2) = \mathbb P (\Sigma_1 ) \mathbb P (\Sigma_2) $, and
	\item $\Sigma_1$ and $\Sigma_2$ are independent given any \textit{complete} dataset $D$, 
	\begin{equation}
		\mathbb P (\Sigma_1, \Sigma_2 | D) = \mathbb P (\Sigma_1 |D) \mathbb P (\Sigma_2 |D) 
	\end{equation}
\end{itemize}

\subsection{Parameter Learning - Discrete Param Sets, Complete Data}
\paragraph{Theorem 18.2.} Given discrete parameter sets and a dataset $D$ of size $N$, we have
\begin{equation}
	\mathbb P (\alpha _{N + 1} | D) = \sum_\theta \pr_\theta (\alpha) \mathbb P (\theta | D)
\end{equation}
where $\alpha_{N + 1}$ is obtained from $\alpha$ by replacing every occurrence of variable $X$ by its instance $X_{N+1}$. Notice that here we are saying $\mathbb P (\alpha _{N + 1} | D) $ is an expectation over $\pr_\theta (\alpha) $.

\paragraph{Bayesian Parameter Estimates.} Let $\theta_{X|\bu}$ b a discrete parameter set. The Bayesian estinate for parameter $\theta_{x | \bu}$ given data set $D$ is defined as 
\begin{equation}
	\theta_{x|\bu}^{be} \triangleq \sum_{\theta_{X| \bu}} \theta_{x | \bu} \cdot \mathbb P ( \theta_{X | \bu} | D)
\end{equation}
where (Theorem 18.4)
\begin{equation}
	\mathbb P( \theta_{X | \bu} | D) = \eta \mathbb P (\theta _{X | \bu}) \prod_x \left[ \theta_{x | \bu} \right] ^{D\# (x \bu)}
\end{equation}
when $\eta$ is a normalizing constant. 

\paragraph{Theorem 18.3.}
\begin{equation}
	\mathbb P (\alpha_{N + 1} | D ) = \pr_{\theta^{be}} (\alpha)
\end{equation}
This is saying that $\mathbb P (\alpha _{N + 1} | D)$ (Theorem 18.2) can be computed as an inference over the network. 

\subsection{Parameter Learning - Continuous Param Sets, Complete Data}
\subsubsection{Dirichlet Prior}
\paragraph{Dirichlet Prior Exponents.}
If our network parameters are binary, then the Dirichlet prior requires to exponents, 
\begin{equation}
	\mathbb E [ \theta_h ] = \frac{\psi_h}{\psi_h + \psi_{\overbar h}} \quad \quad 
	\mathbb E [ \theta_{\overbar h} ] = \frac{\psi_{\overbar h}}{\psi_h + \psi_{\overbar h}}
\end{equation}
This notion generalizes similarly for variables that can take on more values. 

\paragraph{Dirichlet Distribution.} Formally, a Dirichlet prior distribution is specified by a set of exponents $\psi_{x | \bu} \geq 1$. The constraint of the value of exponents guarantees a uni-modal Dirichlet. The \textbf{equivalent sample size} of the distribution is defined as 
\begin{equation}
	\psi_{X | \bu}  \triangleq \sum_ x \phi_{x | \bu}
\end{equation}
The distribution takes the following density
\begin{equation}
	\rho ( \theta _ { X | \bu } ) \triangleq \frac{\Gamma (\psi _ {X | \bu} )}{\prod _ x \Gamma (\psi _ {x | \bu}) } \cdot  \prod_x \left[ \theta _ {x | \bu} \right] ^{\psi_{x | \bu} - 1}
\end{equation}

\paragraph{Dirichlet Statistics.}
If a network parameter has a prior specified in Dirichlet, then it has expectation
\begin{equation}
	\mathbb E ( \theta _{x | \bu} ) = \frac{\psi _ {x | \bu}}{\psi _ {X | \bu}}
\end{equation}
and variance 
\begin{equation}
	\mathbb V (\theta _{x | \bu} ) = \frac{\mathbb E ( \theta _{x | \bu} ) ( 1- \mathbb E ( \theta _{x | \bu} ))}{\psi_{X | \bu } + 1}
\end{equation}
where we notice as the equivalent sample size ($\psi_{X | \bu }$) increase, the variance decreases. The mode is 
\begin{equation}
	\mathbb M ( \theta _{x | \bu} ) = \frac{\psi_{x | \bu} - 1}{\psi _{X | \bu} - |X|}
\end{equation}
where $|X|$ is the number of values for variable $X$. 

\subsubsection{The Learning - Theory}
\paragraph{Theorem 18.7.} 
\begin{equation}
	\mathbb P (\alpha _{N + 1} | D ) = \int \pr_\theta ( \alpha ) \rho ( \theta | D) d \theta
\end{equation}

\paragraph{Bayesian Estimates.} Let $\theta _{X | \bu}$ be a continuous parameter set. The bayesian estimate for network parameter $\theta_{x | \bu}$ given data set $D$ is defined as 
\begin{equation}
	\theta_{x | \bu }^{be} \triangleq \int \theta_{x | \bu} \cdot \rho ( \theta _{X | \bu} | D) d \theta_{X | \bu}
\end{equation}

\paragraph{Theorem 18.8.} 
\begin{equation}
	\mathbb P ( \alpha_{N + 1} | D) = \pr_{\theta^{be}} (\alpha)
\end{equation}

\subsubsection{The Learning - Practice}
\paragraph{Theorem 18.9.} 
Consider a meta network where each parameter set $\theta_{X| \bu}$ has a prior Dirichlet density $\rho ( \theta _ {X | \bu} )$ specified by exponents $\psi_{x | \bu} $. Let $D$ be a complete dataset. Then the posterior density $\rho ( \theta _{X| \bu} | D)$ is also Dirichlet, with exponents
\begin{equation}
	\psi ' _{x | \bu} = \psi _{x|\bu} + D \# (x \bu)
\end{equation}

\paragraph{Posterior Bayesian Estimates.} The posterior expectation of parameter $\theta_{x | \bu}$ given complete data is given by
\begin{equation}
	\theta^{be}_{x | \bu} = \frac{\psi_{x |\bu} + D\# (x \bu)}{\psi_{X | \bu} + D \# (\bu) }
\end{equation}
where $\psi_{x |\bu}$ are the exponents in the prior Dirichlet distribution, and $psi_{X |\bu}$ is its equivalent sample size. 

\paragraph{Maximum-A-Posteriori Estimates.} The MAP estimate given complete data is 
\begin{equation}
	\theta_{x | \bu}^{ma} = \frac{\psi_{x |\bu} + D\# (x \bu) - 1}{\psi_{X | \bu} + D \# (\bu) - |X|}
\end{equation}
where $|X|$ is the number of values for variable $X$.

\subsubsection{Non-informative Prior} 
Non-informative prior refers to the case (in Dirichlet) where all exponents are equal to one: $\psi_{x | \bu} = 1$. Thus the expectation is $1/|X|$ for all classes. Under this prior, 
\begin{equation}
	\theta^{be}_{x|\bu} = \frac{1 + D\#(x \bu)}{|X| + D \# (\bu)}
\end{equation}
and 
\begin{equation}
	\theta_{x|\bu}^{ma} = \frac{D\#(x \bu)}{D\#(\bu)}
\end{equation}
which coincides with the MLE. However, \textit{this only works when the prior exponents are all equal to one.}


\section{Causality - Interventions}
\subsection{Notations}
\paragraph{Causal Effect (CE).} of $X = x$ on $Y = y$ can be written as
\begin{equation}
	\pr (Y = y | do(X = x)) \equiv \pr (y | do (x)) \equiv \pr(y_x)
\end{equation}

\paragraph{Interventional Distribution.} For $\pr (X, Y, Z)$, the interventional distribution for $do(X = x)$ is denoted as 
\begin{equation}
	\pr _{X = x} (Y, Z)
\end{equation}


\subsection{Types of Causal Graphs}\footnote{Hidden variables are roots.}
\subsubsection{Markovian Model}
Each hidden variable in a Markovian Model has at most one child. It has an alternative name of ``no hidden confounders''. In this case, causal effects are always identifiable. 

\subsubsection{Semi-Markovian Model}
Some hidden variable has more than one child. In this case, causal effects are not always identifiable. 

\subsection{Identifiability Criterion}
\subsubsection{Causal Effect Rule}
The Causal Effect Rule links together association and intervention. It states the following: if $\mathbf Z$ are the parents of $X$, then
\begin{equation}
	\pr (y | do(x)) = \pr(y_x) = \sum_{\mathbf z} \pr (y | x, \bz ) \pr (\bz)
\end{equation}
The catch to this formulation is one have to know the parents - meaning that we need to have a correct causal structure prior to using this formula. This is a strong assumption. Often, the structure is exactly what we are after.\footnote{
Recall that different causal structures can generate the same distribution, and data alone is not enough.
} 

\subsubsection{Backdoor Criteria}
A path between $X$ and $Y$ is \textit{\color{Thistle} blocked} by $Z$ iff 
\begin{itemize}
	\item some collider is not in $Z$, or
	\item some non-collider is in $Z$. 
\end{itemize}
where a collider node is simply a convergent valve defined earlier ($\rightarrow W \leftarrow$). Here we distinguish only between colliders and non-colliders. The Backdoor Criteria states the following: Consider a causal graph $G$ and causal effect $\pr(y_x)$. A set of variables $\mathbf Z$ satisfis the backdoor criteria iff 
\begin{itemize}
	\item no node in $\mathbf Z$ is a descendant of $X$, 
	\item $\mathbf Z$ \textit{\color{Thistle} blocks} every path between $X$ and $Y$ that contains an arrow into $X$. 
\end{itemize}
Then, if $\mathbf Z$ is a backdoor, then
\begin{equation}
	\pr ( y _ x) = \sum_{\bz} \pr (y | x, \bz) \pr (\bz)
\end{equation}

\paragraph{Incompleteness.} The backdoor criteria is incomplete. When it identifies that a causal effect has no backdoor, the causal effect can be either identifiable or not identifiable (inconclusive).  


\subsubsection{Frontdoor Criteria}
Consider a causal graph $G$ and causal effect $\pr(y_x)$. A set of variables $\mathbf Z$ satisfies the frontdoor criteria iff \dots. Then if $\mathbf Z$ is a frontdoor, then, 
\begin{equation}
	\pr ( y _ x ) = \sum _ \bz \pr (\bz | x ) \sum_{x'} \pr(y | x', \bz ) \pr(x')
\end{equation}

\subsubsection{Exogenous X\label{sec:exox}}
For the query $\pr (y_x)$, when $X$ is an exogenous variable, meaning that it has no parents, 
\begin{equation}
	\pr(y _x) = \pr (y | x)
\end{equation}

\subsection{The Do-Calculus}
The key idea is to apply a series of rules until we get a formula that is comprised of solely associational quantities. There are three re-write rules in total. $\mathbf X, \mathbf Y, \mathbf Z, \mathbf W$ are disjoint sets of variables, 
\paragraph{Rule 1. Ignoring Observations.}
\begin{equation}
	\pr (\by | do(\bx), \bz, \bw) = \pr (\by | do(\bx) , \bw) \quad \text{if} \quad \dsep_{G_{\overbar{\mathbf X}}} (\mathbf Y, \mathbf {XW}, \mathbf Z)
\end{equation}
where we perform $\dsep$ test on an altered graph $G_{\largeover{\mathbf x}}$, rather than the original causal graph $G$. (Detailed in Section \ref{sec:graph alteration}).

\paragraph{Rule 2. Action / Observation Exchange.}
\begin{equation}
	\pr (\by | do(\bx), do (\bz), \bw) = \pr (\by | do(\bx) ,\bz, \bw) \quad \text{if} \quad \dsep_{G_{\largeover {\mathbf X} \underbar{\mathbf Z}}} (\mathbf Y, \mathbf {XW}, \mathbf Z)
\end{equation}
There are several weakened versions of this rule. First, we consider the case of $\mathbf X = \emptyset$, then
\begin{equation}
	\pr (\by | do (\bz), \bw) = \pr (\by | \bz, \bw) \quad \text{if} \quad \dsep_{G_{\underbar{\mathbf Z}}} (\mathbf Y, \mathbf {W}, \mathbf Z)
\end{equation}
Simplifying even further, we can remove the common ``kept'' part $\mathbf W$, and get
\begin{equation}
		\pr (\by | do (\bz)) = \pr (\by | \bz) \quad \text{if} \quad \dsep_{G_{\underbar{\mathbf Z}}} (\mathbf Y, \emptyset, \mathbf Z)
\end{equation}
notice that this Exogenous X rule (also stated in Section \ref{sec:exox}) follows directly as a corollary of Rule 2. 


\paragraph{Rule 3. Ignoring Actions.}
\begin{equation}
	\pr (\by | do(\bx), do (\bz), \bw) = \pr (\by | do(\bx) , \bw) \quad \text{if} \quad \dsep_{G_{\largeover{\mathbf X} \largeover{Z(W)}}} (\mathbf Y, \mathbf {XW}, \mathbf Z)
\end{equation}
where encounter a special notation $\largeover{Z(W)}$ that means ``not all variables in $\mathbf Z$, but only those variables in $\mathbf Z$ that do not have ancestor in $\mathbf W$''. 

\subsubsection{Graph Alterations}\label{sec:graph alteration} The calculus rules we specified earlier performs dsep tests on altered graphs, where
\begin{itemize}
	\item $G_{\largeover{\mathbf x}}$ is obtained via removing edges pointing into variables $\mathbf X$ from $G$.
	\item $G_{\underbar{\mathbf x}}$ is obtained via removing edges pointing away from variables $\mathbf X$ from $G$.
\end{itemize}

\section{Counterfactual Reasoning}
Causal effects are on the second level: interventions. In counterfactual reasoning, we step up onto level three: what-if's. 

\subsection{The Information Hierarchy}
To add to what we have said above, 
\begin{itemize}
	\item Associational reasoning: Bayesian Network
	\item Interventional reasoning: Causal Bayesian network (causal graph)
	\item Counterfactual reasoning: Functional Bayesian network (functional dependencies)
\end{itemize}

\subsection{Counterfactual Queries}
\subsubsection{Probability of Necessity (PN)}
Probability that $y$ would not have occurred in the absence of $x$ ($do(\overbar x)$), given that $x$ and $y$ did in fact occur, i.e, 
\begin{equation}
	PN = \pr (\overbar y_{\overbar x} | x, y) 
\end{equation}

\subsubsection{Probability of Sufficiency (PS)}
Probability that setting $x$ would produce $y$ in a situation where both $x$ and $y$ are absent, i.e., 
\begin{equation}
	PS = \pr (y_x | \overbar y, \overbar x)
\end{equation}

\subsubsection{Probability of Necessity and Sufficiency (PNS)}
Probability that $y$ responds to $x$ both ways (measures the necessity and sufficiency for $x$ to produce $y$): 
\begin{equation}
	PNS = \pr (y_x, \overbar y_{\overbar x} ) = \pr (x, y) PN + \pr (\overbar x, \overbar y) PS
\end{equation}

\subsubsection{Probability of Disablement} Probability that $y$ would have been prevented if it were not for $x$, 
\begin{equation}
	PD = \pr (\overbar y _ {\overbar x} | y )
\end{equation}

\subsubsection{Probability of Enablement} Probability that $y$ would have been realized if it were not for absence of $x$, 
\begin{equation}
	PE = \pr (y_x | \overbar y) 
\end{equation}


\subsection{Structural Causal Models (SCM)}

\paragraph{World.} In SCM, a world is defined slightly different from what we had in associational graphs. A world is an instantiation of exogenous variables. This is because fixing exogenous variables fully specifies the entire network. 

\subsection{Evenets}
\subsubsection{Observational Event}
\begin{itemize}
	\item Form: $\bx$ where $\mathbf X$ is a set of endogenous variables
	\item Meaning: variables $\mathbf X$ took the value $\bx$
	\item Examples: $x$, \quad $\overbar y, z$
\end{itemize}

\subsubsection{Interventional Event}
\begin{itemize}
	\item Form: $\mathbf y _ \mathbf x$ where $\mathbf X$ and $\mathbf Y $ are sets of endogenous variables
	\item Meaning: variables $\mathbf Y$ took the value $\by$ after setting $\mathbf X = \bx$
	\item Examples: $y_x$, \quad $y_{\overbar x z}$, \quad $(x\overbar y)_{zw}$
\end{itemize}

\subsubsection{Counterfactual Event}
\begin{itemize}
	\item Form: $\eta_1, ..., \eta_n$ where $\eta_i$ is an observational or interventional event
	\item Meaning: $\bigwedge_i \eta_ i$
	\item Examples: mix of above two event examples
\end{itemize}

\subsection{Satisfaction}
Recalling what we had earlier, we denote $\bu$ satisfies event $\eta$ in SCM $\mathcal M$ as 
\begin{equation}
	\mathbf u \vDash_{\mathcal M} \eta
\end{equation}

\subsubsection{Observational Event}
We write 
\begin{equation}
	\bu \vDash_{\mathcal M} \mathbf x
\end{equation}
iff world $\bu$ fixes (endogenous) variables $\mathbf X$ to $\bx$ in SCM $\mathcal M$. 

\subsubsection{Interventional Event}
\begin{equation}
	\bu \vDash_{\mathcal M} \by_\bx \iff \bu \vDash_{\mathcal M_\bx} \by
\end{equation}

\subsubsection{Counterfactual Event}
\begin{equation}
	\bu \vDash_{\mathcal M} \eta_1, ..., \eta_n \iff \bigwedge_i \bu \vDash_{\mathcal M} \eta_i
\end{equation}

\subsection{Queries}
The computation of observational events $\eta$ in SCM is easy. First we compute the table with world probabilities. The table should have a row for each instantiation of the exogenous variables $\bu = [U_1, ..., U_n]$. Endogenous variables, e.g. $X, Y, Z$ will be computed using the factors, for example $f_X(...) = ...$. Then, to compute probability of observational event $\pr(\eta)$, we simply select rows that satisfies $\eta$ and add up their respective $\pr(\bu)$ values. To compute an interventional event $\eta$, we have to first transform the table. This is a two step process, 
\begin{enumerate}
	\item Force the endogenous variable(s) inside $do(\cdot)$ to take value of 1. For example if we want $y_x$, then we have $do(x)$ and thus we set all the values of $X$ in the table to $x$.\footnote{In binary case, this means 1 if we have $do(x)$ and 0 if we have $do(\overbar x)$} 
	\item Now we need to fix the table by adjusting values $y$. We do so by simplifying the relationship, for example
	\begin{equation}
		f_Y(X, U_y, U_x) = xu_r + \overbar x u_y u_r + \overbar x \overbar u _y \overbar u_r
	\end{equation}
	simplifies to 
	\begin{equation}
		f_Y(X = x, U_x, U_r) = u_r
	\end{equation}
\end{enumerate}
Then, the values of $y$ should be computed using this simplified formula (on the altered table). In the new table, this interventional probability can be calculated as if it is an associational query, i.e. we pick rows that satisfies and add up probabilities. 

\subsection{Exogeneity and Monotonicity}
\paragraph{Exogeneity.} $X$ is exogenous relative to $Y$ iff events $y_x$ and $x$ are independent and so are $y_{\overbar x}$ and $x$,
\begin{equation}
	\pr (y_x | x) = \pr (y_x) \quad \text{and} \quad \pr (y_{\overbar x}| x) = \pr ( y_{\overbar x}) 
\end{equation}

\paragraph{Monotonicity.} $Y$ is monotonic relative to $X$ iff the event $\overbar y _ x, y_{\overbar x}$ is unsatisfiable. This notion is general, $x$ and $y$ does not have to be inside the same family. A more general notation is to condition on probability of event $\overbar y _ x, y_{\overbar x}$ being zero. 

\section{Sensitivity Analysis}
\subsection{Global to Local Belief Change}
For each network parameter $\theta_{x | \bu}$, what is the minimal amount of change that can enforce query constraints such as 
\begin{equation}
	\pr (y | e) \geq \varepsilon \quad 
	\pr (y | e) - \pr(z | e ) \geq \varepsilon \quad 
	\pr (y | e) / \pr( z | e) \geq  \varepsilon
\end{equation}
To do so, we need to first calculate partial derivatives where we define $\tau$'s such that 
\begin{equation}
	\theta_{x|\bu} = \tau_{x | \bu} \quad \quad 
	\theta_{\overbar x |\bu} = 1 - \tau_{x | \bu}
\end{equation}
Then, 
\begin{equation}
	\alpha_e = \frac{\partial \pr(e)}{\partial \tau_{x | u}} = \frac{\pr(e, x, u)}{\theta_{x | u}} - \frac{\pr( e, \overbar x, u)}{\theta_{\overbar x | u}}
\end{equation}

This results in the following formulation. To ensure constraint $\pr'(y | e) \geq \varepsilon$, we need to change the meta parameter $\tau_{x |u}$ by $\delta$ such that 
\begin{equation}
	\pr(y, e) - \varepsilon\pr(e) \geq \delta[- \alpha _{y, e} + \varepsilon \alpha _e]
\end{equation}
where $\delta$ is the only unknown and shall result in $\delta \geq q$ or $\delta \leq q$. 

\paragraph{Complexity.} You get this for free. Running inference yields us derivatives and from there we can solve $q$. Hence time complexity is $\mathcal O (n 2^w)$. $n$ is the number of variables and $w$ is the tree width. 

\subsection{Local to Global Belief Change}
Given a change on a parameter, what bounds can we provide on the changes on queries? 

\paragraph{Bounding the Partial Derivative} The bound is in terms of the current value of query $ \pr(\by | \be)$ and the parameter value $ \pr(x| \bu)$
\begin{equation}
	\left| \frac{\partial \pi(\by | \be)}{\partial \tau_{x |\bu}} \right| \leq 
	\frac{\pr(\by | \be) (1 - \pr(\by | \be))}{\pr(x | \bu) (1 - \pr(x | \bu))}
\end{equation}
Extreme queries tend to be robust when changing non-extreme parameters, yet non-extreme queries may change considerably when changing extreme parameters. \footnote{A query that is close to 0 or 1 tends to stick, and a query with value around 1/2 tend to oscillate more. The other way around for parameters. Tinkering parameter that is around 1/2 does not incur big changes, but changing extreme parameters will result in rapid changes.}

\paragraph{Arbitrary Parameter Changes}
First, we recall definition of Odds, 
\begin{equation}
	O(x | \bu) = \pr(x |\bu) / (1 - \pr( x | \bu))
\end{equation}
and \begin{equation}
	O(\by | \be) = \pr( \by | \be) / (1 - \pr( \by | \be))
\end{equation}
and $O'(x | \bu), O'(\by| \be)$ denotes the odds after having applied an arbitrary change to the meta parameter $\tau_{x |\bu}$. The bounds can be specified as 
\begin{equation}
	\left| \ln (O'(\by | \be)) - \ln (O (\by |\be) )\right| \leq \left|\ln (O'( x |\bu)) - \ln ( O(x | \bu))\right| 
\end{equation}

\subsection{Chan-Darwiche Measure}
\begin{equation}
	D_{CD}(\pr, \pr') \triangleq
	\ln\max_w \frac{\pr'(w)}{\pr(w)} - \ln\min_w \frac{\pr'(w)}{\pr(w) }
\end{equation}
which is a true distance metric.\footnote{Original paper: \url{https://www.aaai.org/Papers/AAAI/2002/AAAI02-081.pdf}} Then, we can provide the bound as follows. Let $\pr, \pr'$ be two distributions, $\alpha, \beta$ be any two events, 
\begin{align}
	e^{-D(\pr, \pr')} \leq  \frac{O'(\alpha | \beta)}{O(\alpha | \beta)} \leq e^{D(\pr, \pr')}
\end{align}

As an alternative formulation, given $\pr, \pr'$ and define $p = \pr(\alpha | \beta), d = D_{CD}(\pr, \pr')$, the bounds are 
\begin{equation}
	\frac{pe^{-d}}{pe^{-d} - p + 1} \leq \pr'(\alpha | \beta) \leq \frac{pe^d}{pe^d - p + 1}
\end{equation} 

\paragraph{Distance Between Networks.} Consider the following case
\begin{itemize}
	\item Bayesian network $N'$ is obtained from $N$ by changing the CPT of $X$ from $\Theta_{X | u}$ to $\Theta'_{X | u}$. 
	\item $N$ and $N'$ induce distributions $\pr$ and $\pr'$. 
\end{itemize}
Then, the $D_{CD}$ between the two networks is the same as the distance between the two changed CPTs, i.e. 
\begin{equation}
	D_{CD} (\pr, \pr') = D_{CD} (\Theta_{X | u}, \Theta'_{X | u})
\end{equation}
This works because the changed CPT is indeed itself a distribution. 



















\begin{equation*}
	\heartsuit
\end{equation*}
\end{document}
